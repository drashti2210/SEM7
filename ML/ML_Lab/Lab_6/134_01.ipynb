{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 6 TASK 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kLcVnJAN6Wis"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np \n",
    "import io\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "xKtrBxQD6h1l",
    "outputId": "d650d186-92f5-4451-a82d-6fd749254bf3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EstimatedSalary  Purchased\n",
       "0   19            19000          0\n",
       "1   35            20000          0\n",
       "2   26            43000          0\n",
       "3   27            57000          0\n",
       "4   19            76000          0"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "data=pd.read_csv('/content/drive/My Drive/BuyComputer.csv')\n",
    "data.drop(columns=['User ID',],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zp5l3wPSQv0F"
   },
   "outputs": [],
   "source": [
    "#Label as last column\n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fdx_1zHyRPpH"
   },
   "outputs": [],
   "source": [
    "#X as all columns excluding last\n",
    "X = data.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tBsx4LtRSjG"
   },
   "outputs": [],
   "source": [
    "samples,inputs = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5KlAJ4Q6Rc41"
   },
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data, train_target, test_target = train_test_split(X, y, test_size = 0.30, random_state = 134)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hrVqYdK8SO9R"
   },
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "train_data = sc.fit_transform(train_data)\n",
    "test_data = sc.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8QCETcV-S3aF"
   },
   "outputs": [],
   "source": [
    "train_data = torch.from_numpy(train_data.astype(np.float32))\n",
    "test_data = torch.from_numpy(test_data.astype(np.float32))\n",
    "train_target = torch.from_numpy(train_target.astype(np.float32))\n",
    "test_target = torch.from_numpy(test_target.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDrybe_-TPbV"
   },
   "outputs": [],
   "source": [
    "train_target = train_target.view(train_target.shape[0], 1)\n",
    "test_target = test_target.view(test_target.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsx8bMteTlVO"
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        target_pred = torch.sigmoid(self.linear(x))\n",
    "        return target_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CRDjEMuiTuFp"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegressionModel(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHIUmB6MTxEQ"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "learning_rate = 0.02\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hN0vqZLwUBRp",
    "outputId": "89b7aad5-91df-4589-aeca-7c76df7f0cdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 50, loss = 0.3283\n",
      "epoch: 100, loss = 0.3283\n",
      "epoch: 150, loss = 0.3283\n",
      "epoch: 200, loss = 0.3283\n",
      "epoch: 250, loss = 0.3283\n",
      "epoch: 300, loss = 0.3283\n",
      "epoch: 350, loss = 0.3283\n",
      "epoch: 400, loss = 0.3283\n",
      "epoch: 450, loss = 0.3283\n",
      "epoch: 500, loss = 0.3283\n",
      "epoch: 550, loss = 0.3283\n",
      "epoch: 600, loss = 0.3283\n",
      "epoch: 650, loss = 0.3283\n",
      "epoch: 700, loss = 0.3283\n",
      "epoch: 750, loss = 0.3283\n",
      "epoch: 800, loss = 0.3283\n",
      "epoch: 850, loss = 0.3283\n",
      "epoch: 900, loss = 0.3283\n",
      "epoch: 950, loss = 0.3283\n",
      "epoch: 1000, loss = 0.3283\n",
      "epoch: 1050, loss = 0.3283\n",
      "epoch: 1100, loss = 0.3283\n",
      "epoch: 1150, loss = 0.3283\n",
      "epoch: 1200, loss = 0.3283\n",
      "epoch: 1250, loss = 0.3283\n",
      "epoch: 1300, loss = 0.3283\n",
      "epoch: 1350, loss = 0.3283\n",
      "epoch: 1400, loss = 0.3283\n",
      "epoch: 1450, loss = 0.3283\n",
      "epoch: 1500, loss = 0.3283\n",
      "epoch: 1550, loss = 0.3283\n",
      "epoch: 1600, loss = 0.3283\n",
      "epoch: 1650, loss = 0.3283\n",
      "epoch: 1700, loss = 0.3283\n",
      "epoch: 1750, loss = 0.3283\n",
      "epoch: 1800, loss = 0.3283\n",
      "epoch: 1850, loss = 0.3283\n",
      "epoch: 1900, loss = 0.3283\n",
      "epoch: 1950, loss = 0.3283\n",
      "epoch: 2000, loss = 0.3283\n",
      "epoch: 2050, loss = 0.3283\n",
      "epoch: 2100, loss = 0.3283\n",
      "epoch: 2150, loss = 0.3283\n",
      "epoch: 2200, loss = 0.3283\n",
      "epoch: 2250, loss = 0.3283\n",
      "epoch: 2300, loss = 0.3283\n",
      "epoch: 2350, loss = 0.3283\n",
      "epoch: 2400, loss = 0.3283\n",
      "epoch: 2450, loss = 0.3283\n",
      "epoch: 2500, loss = 0.3283\n",
      "epoch: 2550, loss = 0.3283\n",
      "epoch: 2600, loss = 0.3283\n",
      "epoch: 2650, loss = 0.3283\n",
      "epoch: 2700, loss = 0.3283\n",
      "epoch: 2750, loss = 0.3283\n",
      "epoch: 2800, loss = 0.3283\n",
      "epoch: 2850, loss = 0.3283\n",
      "epoch: 2900, loss = 0.3283\n",
      "epoch: 2950, loss = 0.3283\n",
      "epoch: 3000, loss = 0.3283\n",
      "epoch: 3050, loss = 0.3283\n",
      "epoch: 3100, loss = 0.3283\n",
      "epoch: 3150, loss = 0.3283\n",
      "epoch: 3200, loss = 0.3283\n",
      "epoch: 3250, loss = 0.3283\n",
      "epoch: 3300, loss = 0.3283\n",
      "epoch: 3350, loss = 0.3283\n",
      "epoch: 3400, loss = 0.3283\n",
      "epoch: 3450, loss = 0.3283\n",
      "epoch: 3500, loss = 0.3283\n",
      "epoch: 3550, loss = 0.3283\n",
      "epoch: 3600, loss = 0.3283\n",
      "epoch: 3650, loss = 0.3283\n",
      "epoch: 3700, loss = 0.3283\n",
      "epoch: 3750, loss = 0.3283\n",
      "epoch: 3800, loss = 0.3283\n",
      "epoch: 3850, loss = 0.3283\n",
      "epoch: 3900, loss = 0.3283\n",
      "epoch: 3950, loss = 0.3283\n",
      "epoch: 4000, loss = 0.3283\n",
      "epoch: 4050, loss = 0.3283\n",
      "epoch: 4100, loss = 0.3283\n",
      "epoch: 4150, loss = 0.3283\n",
      "epoch: 4200, loss = 0.3283\n",
      "epoch: 4250, loss = 0.3283\n",
      "epoch: 4300, loss = 0.3283\n",
      "epoch: 4350, loss = 0.3283\n",
      "epoch: 4400, loss = 0.3283\n",
      "epoch: 4450, loss = 0.3283\n",
      "epoch: 4500, loss = 0.3283\n",
      "epoch: 4550, loss = 0.3283\n",
      "epoch: 4600, loss = 0.3283\n",
      "epoch: 4650, loss = 0.3283\n",
      "epoch: 4700, loss = 0.3283\n",
      "epoch: 4750, loss = 0.3283\n",
      "epoch: 4800, loss = 0.3283\n",
      "epoch: 4850, loss = 0.3283\n",
      "epoch: 4900, loss = 0.3283\n",
      "epoch: 4950, loss = 0.3283\n",
      "epoch: 5000, loss = 0.3283\n",
      "epoch: 5050, loss = 0.3283\n",
      "epoch: 5100, loss = 0.3283\n",
      "epoch: 5150, loss = 0.3283\n",
      "epoch: 5200, loss = 0.3283\n",
      "epoch: 5250, loss = 0.3283\n",
      "epoch: 5300, loss = 0.3283\n",
      "epoch: 5350, loss = 0.3283\n",
      "epoch: 5400, loss = 0.3283\n",
      "epoch: 5450, loss = 0.3283\n",
      "epoch: 5500, loss = 0.3283\n",
      "epoch: 5550, loss = 0.3283\n",
      "epoch: 5600, loss = 0.3283\n",
      "epoch: 5650, loss = 0.3283\n",
      "epoch: 5700, loss = 0.3283\n",
      "epoch: 5750, loss = 0.3283\n",
      "epoch: 5800, loss = 0.3283\n",
      "epoch: 5850, loss = 0.3283\n",
      "epoch: 5900, loss = 0.3283\n",
      "epoch: 5950, loss = 0.3283\n",
      "epoch: 6000, loss = 0.3283\n",
      "epoch: 6050, loss = 0.3283\n",
      "epoch: 6100, loss = 0.3283\n",
      "epoch: 6150, loss = 0.3283\n",
      "epoch: 6200, loss = 0.3283\n",
      "epoch: 6250, loss = 0.3283\n",
      "epoch: 6300, loss = 0.3283\n",
      "epoch: 6350, loss = 0.3283\n",
      "epoch: 6400, loss = 0.3283\n",
      "epoch: 6450, loss = 0.3283\n",
      "epoch: 6500, loss = 0.3283\n",
      "epoch: 6550, loss = 0.3283\n",
      "epoch: 6600, loss = 0.3283\n",
      "epoch: 6650, loss = 0.3283\n",
      "epoch: 6700, loss = 0.3283\n",
      "epoch: 6750, loss = 0.3283\n",
      "epoch: 6800, loss = 0.3283\n",
      "epoch: 6850, loss = 0.3283\n",
      "epoch: 6900, loss = 0.3283\n",
      "epoch: 6950, loss = 0.3283\n",
      "epoch: 7000, loss = 0.3283\n",
      "epoch: 7050, loss = 0.3283\n",
      "epoch: 7100, loss = 0.3283\n",
      "epoch: 7150, loss = 0.3283\n",
      "epoch: 7200, loss = 0.3283\n",
      "epoch: 7250, loss = 0.3283\n",
      "epoch: 7300, loss = 0.3283\n",
      "epoch: 7350, loss = 0.3283\n",
      "epoch: 7400, loss = 0.3283\n",
      "epoch: 7450, loss = 0.3283\n",
      "epoch: 7500, loss = 0.3283\n",
      "epoch: 7550, loss = 0.3283\n",
      "epoch: 7600, loss = 0.3283\n",
      "epoch: 7650, loss = 0.3283\n",
      "epoch: 7700, loss = 0.3283\n",
      "epoch: 7750, loss = 0.3283\n",
      "epoch: 7800, loss = 0.3283\n",
      "epoch: 7850, loss = 0.3283\n",
      "epoch: 7900, loss = 0.3283\n",
      "epoch: 7950, loss = 0.3283\n",
      "epoch: 8000, loss = 0.3283\n",
      "epoch: 8050, loss = 0.3283\n",
      "epoch: 8100, loss = 0.3283\n",
      "epoch: 8150, loss = 0.3283\n",
      "epoch: 8200, loss = 0.3283\n",
      "epoch: 8250, loss = 0.3283\n",
      "epoch: 8300, loss = 0.3283\n",
      "epoch: 8350, loss = 0.3283\n",
      "epoch: 8400, loss = 0.3283\n",
      "epoch: 8450, loss = 0.3283\n",
      "epoch: 8500, loss = 0.3283\n",
      "epoch: 8550, loss = 0.3283\n",
      "epoch: 8600, loss = 0.3283\n",
      "epoch: 8650, loss = 0.3283\n",
      "epoch: 8700, loss = 0.3283\n",
      "epoch: 8750, loss = 0.3283\n",
      "epoch: 8800, loss = 0.3283\n",
      "epoch: 8850, loss = 0.3283\n",
      "epoch: 8900, loss = 0.3283\n",
      "epoch: 8950, loss = 0.3283\n",
      "epoch: 9000, loss = 0.3283\n",
      "epoch: 9050, loss = 0.3283\n",
      "epoch: 9100, loss = 0.3283\n",
      "epoch: 9150, loss = 0.3283\n",
      "epoch: 9200, loss = 0.3283\n",
      "epoch: 9250, loss = 0.3283\n",
      "epoch: 9300, loss = 0.3283\n",
      "epoch: 9350, loss = 0.3283\n",
      "epoch: 9400, loss = 0.3283\n",
      "epoch: 9450, loss = 0.3283\n",
      "epoch: 9500, loss = 0.3283\n",
      "epoch: 9550, loss = 0.3283\n",
      "epoch: 9600, loss = 0.3283\n",
      "epoch: 9650, loss = 0.3283\n",
      "epoch: 9700, loss = 0.3283\n",
      "epoch: 9750, loss = 0.3283\n",
      "epoch: 9800, loss = 0.3283\n",
      "epoch: 9850, loss = 0.3283\n",
      "epoch: 9900, loss = 0.3283\n",
      "epoch: 9950, loss = 0.3283\n",
      "epoch: 10000, loss = 0.3283\n",
      "accuracy: 0.8500\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    target_pred = model(train_data)\n",
    "    loss = criterion(target_pred, train_target)\n",
    "  \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    target_predicted = model(test_data)\n",
    "    target_predicted_cls = target_predicted.round()\n",
    "    acc = target_predicted_cls.eq(test_target).sum() / float(test_target.shape[0])\n",
    "    print(f'accuracy: {acc.item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "134_01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
